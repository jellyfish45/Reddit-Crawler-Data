# Reddit-Crawler-Data
In this repository, we are going to store Jupyter notebook regarding the crawling process and the dataset we get to help with future analysis.  
## Creation Timeline 
(1)scrape_reddit.ipynb: Scraping data with a theme of "suicide" from reddit. And find relevant topics about it.

(2)sub_gather.ipynb: Dig deep into the topics and gather the data.   

(3)posts_influence.ipynb: Try to track the influence of the most influencial submissions to their comment authors (Problem: need to scape more data and use more specific emotion analyzing tool)   

(4)sub_analyze.ipynb: Find keywords/valuable Issues related with the topics seperately. ï¼ˆProblem: need to dig deep) 

(5)posts-influence: Try to analyze the posts'influence using "empath-client"

Other ipynb files are just auxiliary tools.
All the csv documents are the data I collected.
