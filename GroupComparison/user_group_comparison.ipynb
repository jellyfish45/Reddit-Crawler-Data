{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inputs here\n",
    "control = [[],[]] #array of people in control for each one we will examine\n",
    "treatment = [[],[]] #array of people in treatement for each one we will examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.7.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting prawcore<3,>=2.1 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update-checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting websocket-client>=0.54.0 (from praw)\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\logan\\documents\\research\\.venv\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\logan\\documents\\research\\.venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\logan\\documents\\research\\.venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\logan\\documents\\research\\.venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\logan\\documents\\research\\.venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
      "Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
      "   ---------------------------------------- 0.0/191.0 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 92.2/191.0 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 191.0/191.0 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.3/57.3 kB ? eta 0:00:00\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0 websocket-client-1.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw  #Python Reddit API Wrappe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"54u8-WeUDusPlUoFQDZu4w\",\n",
    "    client_secret=\"lGhkiE6scCkSMYsj0P9AXzyYVSLBag\",\n",
    "    user_agent=\"jellyfish\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = reddit.redditor('Sariel007')\n",
    "#https://praw.readthedocs.io/en/stable/code_overview/reddit/user.html#praw.models.User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trophy(name='13-Year Club'), Trophy(name='Best Link'), Trophy(name='Inciteful Link'), Trophy(name='RedditGifts 2009-2022'), Trophy(name='Quantum Potato'), Trophy(name='Golden Potato'), Trophy(name=\"Place '22\"), Trophy(name=\"Place '17\"), Trophy(name=\"First Placer '22\"), Trophy(name='Argentium Club'), Trophy(name='Wearing is Caring'), Trophy(name='100 Awards Club'), Trophy(name='Secret Santa'), Trophy(name='Gilding VIII'), Trophy(name='Reddit Premium'), Trophy(name='Well-rounded'), Trophy(name='Best Link'), Trophy(name='Best Link'), Trophy(name='Well-rounded'), Trophy(name='Team Orangered'), Trophy(name='Verified Email')]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in user.trophies()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VALID_TIME_FILTERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_listing_use_sort', '_path', '_prepare', '_reddit', '_safely_add_arguments', '_validate_time_filter', 'controversial', 'hot', 'new', 'parse', 'top']\n",
      "['MISSING_COMMENT_MESSAGE', 'STR_FIELD', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_extract_submission_id', '_fetch', '_fetch_data', '_fetch_info', '_fetched', '_kind', '_reddit', '_replies', '_reset_attributes', '_safely_add_arguments', '_submission', '_url_parts', '_vote', 'all_awardings', 'approved_at_utc', 'approved_by', 'archived', 'associated_award', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'award', 'awarders', 'banned_at_utc', 'banned_by', 'block', 'body', 'body_html', 'can_gild', 'can_mod_post', 'clear_vote', 'collapse', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'collapsed_reason_code', 'comment_type', 'controversiality', 'created', 'created_utc', 'delete', 'disable_inbox_replies', 'distinguished', 'downs', 'downvote', 'edit', 'edited', 'enable_inbox_replies', 'fullname', 'gild', 'gilded', 'gildings', 'id', 'id_from_url', 'is_root', 'is_submitter', 'likes', 'link_author', 'link_id', 'link_permalink', 'link_title', 'link_url', 'locked', 'mark_read', 'mark_unread', 'mod', 'mod_note', 'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_comments', 'num_reports', 'over_18', 'parent', 'parent_id', 'parse', 'permalink', 'quarantine', 'refresh', 'removal_reason', 'replies', 'reply', 'report', 'report_reasons', 'save', 'saved', 'score', 'score_hidden', 'send_replies', 'stickied', 'submission', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_type', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unblock_subreddit', 'uncollapse', 'unrepliable_reason', 'unsave', 'ups', 'upvote', 'user_reports']\n",
      "False\n",
      "NRA Says New Florida Law Would Take Away Rifles From '10-Year-Old Little Girls' on Their Birthdays\n",
      "False\n",
      "[]\n",
      "10516\n",
      "False\n",
      "0\n",
      "10516\n",
      "0\n",
      "1566045959.0\n",
      "Here is where your NRA donations and fees go. \n",
      "\n",
      "[NRA Spent Tens of Thousands on Hair and Makeup for CEOâ€™s Wife](https://www.thedailybeast.com/nra-spent-tens-of-thousands-on-hair-and-makeup-for-ceo-wayne-lapierres-wife-susan)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Comment' object has no attribute 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\logan\\Documents\\Research\\Mental_Health\\Reddit_Data_Scraping\\Reddit-Crawler-Data\\GroupComparison\\user_group_comparison.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/logan/Documents/Research/Mental_Health/Reddit_Data_Scraping/Reddit-Crawler-Data/GroupComparison/user_group_comparison.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(comment\u001b[39m.\u001b[39mcreated_utc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/logan/Documents/Research/Mental_Health/Reddit_Data_Scraping/Reddit-Crawler-Data/GroupComparison/user_group_comparison.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(comment\u001b[39m.\u001b[39mbody)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/logan/Documents/Research/Mental_Health/Reddit_Data_Scraping/Reddit-Crawler-Data/GroupComparison/user_group_comparison.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(comment\u001b[39m.\u001b[39;49mtitle)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/logan/Documents/Research/Mental_Health/Reddit_Data_Scraping/Reddit-Crawler-Data/GroupComparison/user_group_comparison.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\logan\\Documents\\Research\\.venv\\Lib\\site-packages\\praw\\models\\reddit\\base.py:37\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[1;34m(self, attribute)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch()\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attribute)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     38\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Comment' object has no attribute 'title'"
     ]
    }
   ],
   "source": [
    "print(dir(user.submissions))\n",
    "for comment in user.comments.top():\n",
    "    print(dir(comment))\n",
    "    #edited, link_title, over_18, replies, score, score_hidden, total_awards_received, \n",
    "    print(comment.edited)\n",
    "    print(comment.link_title)\n",
    "    print(comment.over_18)\n",
    "    print(comment.replies.list())\n",
    "    print(comment.score)\n",
    "    print(comment.score_hidden)\n",
    "    print(comment.total_awards_received)\n",
    "    print(comment.ups)\n",
    "    print(comment.downs)\n",
    "    print(comment.created_utc)\n",
    "    print(comment.body)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class to map a string based Enum to an integer\n",
    "class Enum:\n",
    "\n",
    "    #class variable to map enum names to potential enu\n",
    "    find_name = dict()\n",
    "    def __init__(self, name):\n",
    "        assert(not name in Enum.find_name)\n",
    "        Enum.find_name[name] = self\n",
    "        self.names = dict()\n",
    "        self.int_to_name = dict() #array would be more efficieny\n",
    "    \n",
    "    #map the name to a number\n",
    "    def get_val(self, enum):\n",
    "        if (not enum in self.names):\n",
    "            self.int_to_name[len(self.names)+1] = enum\n",
    "            self.names[enum] = len(self.names) + 1\n",
    "        return self.names[enum]\n",
    "    \n",
    "    #get the number of enums in this class\n",
    "    def get_num_enums(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def get_enum(name):\n",
    "        return Enum.find_name[name] if name in Enum.find_name else Enum(name)\n",
    "    \n",
    "sw = Enum.get_enum(\"star wars\")\n",
    "sw.get_val(\"kenobi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.get_num_enums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_txt(txt:str):\n",
    "    assert False, \"use the lexicon Jiayi uses for results - note this is current but idk there is way to get past one\"\n",
    "\n",
    "def get_expanded_data_redditor(redditor: praw.models.Redditor):\n",
    "    #comments\n",
    "    #submissions\n",
    "    pass\n",
    "\n",
    "def get_expaneded_data_user(user: praw.models.User):\n",
    "    #blocked analysis potentially\n",
    "    #contributor subreddit analysis\n",
    "    #karma dict analysis\n",
    "    #num_moderator_subreddit\n",
    "    #subreddits\n",
    "    #trusted\n",
    "    pass\n",
    "\n",
    "def get_base_data_redditor(redditor: praw.models.Redditor):\n",
    "    to_ret = dict()\n",
    "    to_ret[\"comment_karma\"] = redditor.comment_karma\n",
    "    to_ret[\"time_creation\"] = redditor.created_utc\n",
    "    to_ret[\"verified_email\"] = redditor.has_verified_email\n",
    "    to_ret[\"is_employee\"] = redditor.is_employee\n",
    "    to_ret[\"is_mod\"] = redditor.is_mod\n",
    "    to_ret[\"is_gold\"] = redditor.is_gold \n",
    "    to_ret[\"is_suspended\"] = redditor.is_suspended\n",
    "    to_ret[\"link_karma\"] = redditor.link_karma\n",
    "    to_ret[\"num_moderated\"] = len(redditor.moderated()) # TODO - analyze\n",
    "    to_ret[\"num_multireddits\"] = len(redditor.multireddits()) #TODO - analyze\n",
    "    to_ret[\"num_trophies\"] = len(redditor.trophies()) # TODO - analyze the kind a trophies\n",
    "    \n",
    "    \n",
    "    if (redditor.subreddit):\n",
    "        to_ret[\"has_subreddit\"] = True\n",
    "        to_ret[\"over_18\"] = redditor.subreddit[\"over_18\"]\n",
    "        to_ret[\"num_subscribers\"] = redditor.subreddit[\"subscribers\"]\n",
    "        #analyze public description\n",
    "        #analyze title\n",
    "    else:\n",
    "        to_ret[\"has_subreddit\"] = False\n",
    "\n",
    "    return to_ret\n",
    "\n",
    "# def get_base_data_user(user: praw.models.User):\n",
    "#     to_ret = dict()\n",
    "#     to_ret[\"num_blocked\"] = len(user.blocked())\n",
    "\n",
    "#     #allowed to post to subreddit (private/unrestricted) or prevent antispam removal\n",
    "#     to_ret[\"num_contributor_subreddits\"] = len(user.contributor_subreddits())\n",
    "\n",
    "#     to_ret[\"num_friends\"] = len(user.friends())\n",
    "    \n",
    "#     to_ret[\"num_moderator_subreddit\"] = len(user.moderator_subreddits())\n",
    "\n",
    "#     to_ret[\"num_multireddits\"] = len(user.multireddits())\n",
    "\n",
    "#     #TODO - preferences()\n",
    "#     # assert False, \"need to add preferenced\"\n",
    "\n",
    "#     to_ret[\"num_subreddits_subscribed_to\"] = len(user.subreddits())\n",
    "\n",
    "#     to_ret[\"num_trusted\"] = len(user.trusted())\n",
    "\n",
    "#     preferences = user.preferences()\n",
    "\n",
    "#     #preferences enum\n",
    "#     for pref_choice in [\"accept_pms\",\"default_comment_sort\", \"geopopular\"]:\n",
    "#         _key = \"pref_\" + pref_choice\n",
    "#         to_ret[_key] = Enum.get_enum(_key).get_val(preferences[pref_choice])\n",
    "\n",
    "#     for pref_choice in [\"activity_relevant_ads\", \"allow_clicktracking\", \"over_18\", \"research\", \"search_include_over_18\"] + [\"hide_downs\", \"hide_ads\", \"hide_from_robots\", \"highlight_controversial\", \"label_nsfw\", \"top_karma_subreddits\"]:\n",
    "#         _key = \"pref_\" + pref_choice\n",
    "#         to_ret[_key] = preferences[pref_choice]\n",
    "\n",
    "#     \"\"\" \n",
    "#     accept_pms: ENUM[everyone, whitelisted]\n",
    "#     activity_relevant_ads: bool \n",
    "#     allow_clicktracking: bool \n",
    "#     # beta: bool \n",
    "#     clickgadget: bool\n",
    "#     default_comment_sort: ENUM[confidence, top, new, controversial, old, random, qa, live]\n",
    "#     over_18: bool\n",
    "#     public_votes: bool\n",
    "#     research: bool \n",
    "#     search_include_over_18: bool \n",
    "#     # video_autoplay: bool\n",
    "#     geopopular: ENUM[lots of US locations + global]\n",
    "#     hide_downs: bool\n",
    "#     hide_ads: bool\n",
    "#     hide_from_robots: bool\n",
    "#     highlight_controversial: bool \n",
    "#     # highlight_new_comments: bool \n",
    "#     label_nsfw: bool\n",
    "#     email_user_new_follower: bool\n",
    "#     top_karma_subreddits: bool \n",
    "\n",
    "\n",
    "#     __\n",
    "#     idk what these r but could be significant???\n",
    "#     __\n",
    "#     show_presence? bool \n",
    "#     show_promote? bool\n",
    "#     show_link_flair? bool\n",
    "#     \"\"\"\n",
    "\n",
    "#     return to_ret\n",
    "\n",
    "def get_base_data(user_name: str):\n",
    "    return get_base_data_user().update(get_base_data_redditor(reddit.redditor('Sariel007')))\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes to self\n",
    "should have two datasets - an extended dataset (i.e. once we get a lot of data we can use)\n",
    "a base stats - those stats I would think are essential for use on a more limitted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_user = dict() #id -> [\"additional\": dict(): str:number, \"limitted\": dict(): str:number]\n",
    "\n",
    "def query_stats(query):\n",
    "    \"\"\"if list do all, else fill dict with all stats/user\n",
    "        not thread safe (id)\"\"\"\n",
    "    \n",
    "\n",
    "    #recurse to string\n",
    "    if (isinstance(query, type(list()))):\n",
    "        map(query_stats, query)\n",
    "        return \n",
    "\n",
    "    user_name = query\n",
    "\n",
    "    #already have stats\n",
    "    if (user_name in stats_by_user): return\n",
    "\n",
    "    user_attributes = dict()\n",
    "\n",
    "    \n",
    "\n",
    "    #for user\n",
    "\n",
    "    #user.trusted() and analysis (gives name and date of trust)\n",
    "        #sort it so can find relevant date info quickly\n",
    "\n",
    "    #.subreddits() - list of subreddits subscribed to, numnber, some kind of sentiment attatchment\n",
    "    \"\"\"\n",
    "        submission.title, submission.public_description, over18\n",
    "    \"\"\"\n",
    "    #some kind of sentiment analysis on it, number of them\n",
    "    #.preferences(): all prefs, naivvely include all but then filter\n",
    "    \"\"\" (https://praw.readthedocs.io/en/stable/code_overview/other/preferences.html#praw.models.Preferences)\n",
    "        part rel. (prob just include all if have enough users tho)\n",
    "            accept_pms: enum [everyone, whitelisted]\n",
    "            activity_relevant_ads\n",
    "            allow_clicktracking\n",
    "            clickgadget\n",
    "            creddit_autorenew\n",
    "            default_comment_sort: enum \n",
    "            domain_details\n",
    "            email_digests\n",
    "            email_post_reply\n",
    "            email_private_message\n",
    "            email_upvote_comment\n",
    "            email_upvote_post\n",
    "            email_username_mention\n",
    "            enable_default_themes\n",
    "            geopopular: enum\n",
    "            hide_ads\n",
    "            hide_downs\n",
    "            hide_from_robots\n",
    "            hide_upshighlight_controversial\n",
    "            min_comment_score: number [-100,100]\n",
    "            no_profanity\n",
    "            monitor_mentions\n",
    "            nightmode\n",
    "            num_comments: [1,500]\n",
    "            over_18\n",
    "            public_votes\n",
    "            research\n",
    "            search_include_over_18\n",
    "            show_trending\n",
    "            store_visits\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #.multireddit() -> controversial, author ids, \n",
    "\n",
    "    #.blocked() -> number of blocked\n",
    "\n",
    "    #.friends()\n",
    "\n",
    "    #.karma()\n",
    "    \n",
    "    #moderator_subreddits\n",
    "\n",
    "\n",
    "    #https://praw.readthedocs.io/en/stable/code_overview/models/redditor.html\n",
    "    #comments(), controversial(), downvoted(), moderated(), saved(), submissions()?, trophies()?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    stats_by_user[user_name] = user_attributes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
